{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyopencl.Device 'HD Graphics 4000' on 'Apple' at 0x1024400>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jug/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pyopencl/__init__.py:207: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n",
      "  \"to see more.\", CompilerWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not open /Users/jug/.spimagine\n",
      "<pyopencl.Device 'HD Graphics 4000' on 'Apple' at 0x1024400>\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ni\n",
    "import maxflow\n",
    "\n",
    "from tifffile import imread, imsave\n",
    "import cPickle as pickle\n",
    "\n",
    "from skimage.filters import gaussian_filter\n",
    "\n",
    "from spimagine import volshow\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# %matplotlib inline\n",
    "# %pylab inline\n",
    "# pylab.rcParams['figure.figsize'] = (5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sampled unit sphere and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "\n",
    "INF = 10000000\n",
    "filename = \"sample3d_cup1.tif\"\n",
    "\n",
    "# load pickeled unit sphere sampling\n",
    "with open('sphere_sampling.pkl','r') as f:\n",
    "    dictSphereData = pickle.load(f)\n",
    "    \n",
    "# sampling parameters\n",
    "num_columns = dictSphereData['n']\n",
    "col_vectors = dictSphereData['points']\n",
    "neighbors = dictSphereData['neighbors']\n",
    "num_neighbors = len(neighbors)/num_columns\n",
    "K = 10       # as in Wu & Chen 2002\n",
    "\n",
    "# net surface related parameters\n",
    "max_delta_k = 4\n",
    "\n",
    "# positioning of net in image\n",
    "center_x = 130\n",
    "center_y = 160\n",
    "center_z = 12\n",
    "max_r_x = 40\n",
    "max_r_y = 40\n",
    "max_r_z = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   3.    2.    5.    1.    8.    6.]\n",
      " [   6.    4.    0.    9.    3.    2.]\n",
      " [   7.    0.   10.    5.   15.    4.]\n",
      " ..., \n",
      " [ 504.  511.  501.  506.  496.  507.]\n",
      " [ 505.  507.  511.  502.  508.  509.]\n",
      " [ 508.  509.  506.  510.  503.  505.]]\n"
     ]
    }
   ],
   "source": [
    "neighbors_of = np.ones([num_columns,num_neighbors]) * -1\n",
    "for i,p1 in enumerate(col_vectors):\n",
    "    dists = []\n",
    "    for j,p2 in enumerate(col_vectors):\n",
    "        dists.append( [i, j, np.dot(p1,p2)] )\n",
    "    sorted_dists = sorted(dists, key=lambda dists: -dists[2])\n",
    "    for idx in range(1,1+num_neighbors):\n",
    "        neighbors.append(sorted_dists[idx])\n",
    "    for idx in range(num_neighbors):\n",
    "        neighbors_of[i,idx] = sorted_dists[idx+1][1]\n",
    "\n",
    "print neighbors_of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading image to be segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions:  (25, 335, 275)\n",
      "Image min/max:     199 481\n"
     ]
    }
   ],
   "source": [
    "sigma = 2.\n",
    "image = imread(filename)\n",
    "image_smooth = gaussian_filter(image,sigma)\n",
    "print 'Image dimensions: ', image.shape\n",
    "print 'Image min/max:    ', np.min(image), np.max(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volwin = volshow(image, stackUnits = [1.,1.,4.], raise_window=False)\n",
    "# volwin = volshow(image_smooth, stackUnits = [1.,1.,4.], raise_window=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading membrane probs computed with ilastik** (just testing...;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_memprob = np.load(\"sample3d_cup1_Probabilities.npy\")[:,:,:,0]\n",
    "volwin = volshow(image_memprob, stackUnits = [1.,1.,4.], raise_window=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bresenham as bham\n",
    "from myfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 5, 3],\n",
       "       [7, 5, 2],\n",
       "       [6, 4, 2],\n",
       "       [5, 3, 2],\n",
       "       [4, 3, 1],\n",
       "       [3, 2, 1],\n",
       "       [2, 1, 1],\n",
       "       [1, 1, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bham.bresenhamline(np.array([[9,6,3]]), np.array([[0,0,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute weights *w*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-269. -259. -270. ..., -245. -250. -253.]\n",
      " [-269. -269. -260. ..., -252. -251. -251.]\n",
      " [-273. -265. -267. ..., -252. -249. -254.]\n",
      " ..., \n",
      " [-254. -262. -246. ..., -260. -257. -271.]\n",
      " [-254. -251. -250. ..., -256. -252. -259.]\n",
      " [-254. -247. -241. ..., -259. -256. -278.]] -411.0 -234.0\n",
      "[[-269.   10.  -11. ...,   -1.   -5.   -3.]\n",
      " [-269.    0.    9. ...,   -5.    1.    0.]\n",
      " [-273.    8.   -2. ...,    0.    3.   -5.]\n",
      " ..., \n",
      " [-254.   -8.   16. ...,   -6.    3.  -14.]\n",
      " [-254.    3.    1. ...,   -2.    4.   -7.]\n",
      " [-254.    7.    6. ...,   -1.    3.  -22.]]\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros([num_columns, K]) # node weights\n",
    "w_tilde = np.zeros([num_columns, K])\n",
    "\n",
    "# fill in node weights\n",
    "for i in range(num_columns):\n",
    "    to_x = int(center_x + col_vectors[i,0]*max_r_x)\n",
    "    to_y = int(center_y + col_vectors[i,1]*max_r_y)\n",
    "    to_z = int(center_z + col_vectors[i,2]*max_r_z)\n",
    "#     print 'from (', center_x, center_y, center_z, ') to (', to_x, to_y, to_z, ')'\n",
    "    coords = bham.bresenhamline(np.array([[center_x, center_y, center_z]]), np.array([[to_x, to_y, to_z]]))\n",
    "    num_pixels = len(coords)\n",
    "    for k in range(K):\n",
    "        start = int(k * float(num_pixels)/K)\n",
    "        end = max( start+1, start + num_pixels/K )\n",
    "        w[i,k] = -1 * compute_weight( image, coords[start:end])\n",
    "#         print '   coords:        ', coords[start:end]\n",
    "#         print '   indizes and w: ', start, end, w[i,k]\n",
    "#     break\n",
    "        \n",
    "for i in range(num_columns):\n",
    "    w_tilde[i,0] = w[i,0] \n",
    "    for k in range(1,K):\n",
    "        w_tilde[i,k] = w[i,k]-w[i,k-1]\n",
    "\n",
    "print w, np.min(w), np.max(w)\n",
    "print w_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build flow network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_nodes = num_columns*K\n",
    "num_edges = (num_nodes*num_neighbors*(max_delta_k+max_delta_k+1))/2\n",
    "\n",
    "g = maxflow.Graph[float](num_nodes,num_edges)\n",
    "nodes = g.add_nodes(num_nodes)\n",
    "\n",
    "for i in range(num_columns):\n",
    "\n",
    "    # connect column to s,t\n",
    "    for k in range(K):\n",
    "        if w_tilde[i,k] < 0:\n",
    "            g.add_tedge(i*K+k, -w_tilde[i,k], 0)\n",
    "        else:\n",
    "            g.add_tedge(i*K+k, 0, w_tilde[i,k])\n",
    "            \n",
    "    # connect column to i-chain\n",
    "    for k in range(1,K):\n",
    "        g.add_edge(i*K+k, i*K+k-1, INF, 0)\n",
    "        \n",
    "    # connect column to neighbors\n",
    "    for k in range(K):\n",
    "        for j in neighbors_of[i]:\n",
    "            k2 = max(0,k-max_delta_k)\n",
    "            g.add_edge(i*K+k, j*K+k2, INF, 0)\n",
    "            # print i,k,int(j),k2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve and show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of s and t component:  3230 1890\n"
     ]
    }
   ],
   "source": [
    "maxval = g.maxflow()\n",
    "\n",
    "size_s_comp = 0\n",
    "size_t_comp = 0\n",
    "for n in nodes:\n",
    "    seg = g.get_segment(n)\n",
    "    if seg == 0:\n",
    "        size_s_comp += 1\n",
    "    else:\n",
    "        size_t_comp += 1\n",
    "    #print \"Segment of the node \",n,\":\", seg\n",
    "print \"Size of s and t component: \", size_s_comp, size_t_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgout = np.zeros(image.shape)\n",
    "for i in range(num_columns):\n",
    "    for k in range(K):\n",
    "        x = int(center_x + col_vectors[i,0] * k/float(K) * max_r_x)\n",
    "        y = int(center_y + col_vectors[i,1] * k/float(K) * max_r_y)\n",
    "        z = int(center_z + col_vectors[i,2] * k/float(K) * max_r_z)\n",
    "        seg = g.get_segment(i*K+k)\n",
    "        if seg == 0:\n",
    "            if x>=0 and y>=0 and z>=0 and \\\n",
    "               x<image.shape[2] and y<image.shape[1] and z<image.shape[0]:\n",
    "                imgout[z,y,x] = 1\n",
    "# IDEE: draw line to all neighbors (at height k) along 3d bresenham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volwin = volshow(imgout, stackUnits = [1.,1.,4.], raise_window=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
